# NewsClassifier: ClassificaÃ§Ã£o de NotÃ­cias com Processamento de Linguagem Natural

#### ğŸ¯ Objetivo

Classificar automaticamente notÃ­cias em diferentes categorias (esportes, negÃ³cios, polÃ­tica, tecnologia, etc.) usando tÃ©cnicas de Processamento de Linguagem Natural (NLP) e algoritmos de machine learning.

---

### âš™ï¸Criando env

```
conda create --name cases_data_science python=3.10
conda activate cases_data_science
```

Se precisar deletar env

```
conda remove --name cases_data_science --all
```

Exportar notebook para md

```
jupyter nbconvert 01_eda_preprocessing_modeling.ipynb --to markdown --no-input

```

Criando env com environment.yml

```
conda env create -f environment.yml
conda activate nome_env
```

---

#### ğŸ“Š Fonte dos Dados

- Dataset: [AG News Corpus](https://www.kaggle.com/datasets/amananandrai/ag-news-classification-dataset) ou via `torchtext.datasets.AG_NEWS`
- 4 categorias: World, Sports, Business, Sci/Tech
- ~120.000 exemplos rotulados

---

### ğŸ—‚ï¸ Estrutura de Pastas e Arquivos

```
nlp-text-classification-news/
â”‚
â”œâ”€â”€ data/                # Dados brutos e tratados
â”‚   â”œâ”€â”€ raw/
â”‚   â””â”€â”€ processed/
â”‚
â”œâ”€â”€ notebooks/           # Notebooks principais
â”‚   â”œâ”€â”€ 01_eda_preprocessing_modeling.ipynb
â”‚
â”œâ”€â”€ models/              # Modelos treinados (opcional)
â”‚
â”œâ”€â”€ reports/
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ utils.py             # FunÃ§Ãµes auxiliares

```

---

#### âš™ï¸ Processos IncluÃ­dos

- ExploraÃ§Ã£o dos dados textuais (wordclouds, frequÃªncia de palavras)
- PrÃ©-processamento com NLTK ou spaCy
- VetorizaÃ§Ã£o com TF-IDF
- Modelagem com:
  - RegressÃ£o LogÃ­stica (baseline)
  - Random Forest
  - XGBoost
- AvaliaÃ§Ã£o: accuracy, F1-score, matriz de confusÃ£o
- VisualizaÃ§Ãµes com seaborn e matplotlib

---

### âš™ï¸ Como Executar Localmente

1. Clone o repositÃ³rio:

```
git clone https://github.com/seuusuario/nlp-text-classification-news.git
cd nlp-text-classification-news
```

2. Crie um ambiente virtual (opcional) e instale as dependÃªncias:

```
pip install -r requirements.txt
```

3. Inicie os notebooks:
   ```
   jupyter notebook
   ```

Abra os notebooks na pasta `notebooks/` e execute em ordem.

### ğŸ“Š Salvar grÃ¡ficos

Plotly precisa da biblioteca **kaleido** para exportar grÃ¡ficos como imagem:

```
pip install -U kaleido
```

---

## ğŸ“Š Resultados da Modelagem

Foram avaliados diferentes algoritmos de classificaÃ§Ã£o para categorizar notÃ­cias da base AG News, utilizando vetorizaÃ§Ã£o TF-IDF e mÃ©tricas de desempenho como AcurÃ¡cia, PrecisÃ£o, RevocaÃ§Ã£o e F1-Score. Os modelos testados foram:

- **Logistic Regression**
- **Multinomial Naive Bayes**
- **Random Forest**
- **Linear SVM**

### ğŸ“Œ DistribuiÃ§Ã£o das Classes no Treinamento

A distribuiÃ§Ã£o das categorias no conjunto de treino Ã© relativamente equilibrada:

<img src="./reports/figures/class_distribution_train.png" alt="DistribuiÃ§Ã£o de Classes" width="550"/>

### ğŸ¯ MÃ©tricas por Modelo

#### ğŸ”¹ Logistic Regression

**AcurÃ¡cia** : 0.9041

<img src="./reports/figures/confusion_matrix_Logistic_Regression.png" alt="Matriz de ConfusÃ£o - Logistic Regression" width="650"/>

---

#### ğŸ”¹ Multinomial Naive Bayes

**AcurÃ¡cia** : 0.8882

<img src="./reports/figures/confusion_matrix_Multinomial_Naive_Bayes.png" alt="Matriz de ConfusÃ£o - Naive Bayes" width="650"/>

---

#### ğŸ”¹ Random Forest

**AcurÃ¡cia** : 0.8667

<img src="./reports/figures/confusion_matrix_Random_Forest.png" alt="Matriz de ConfusÃ£o - Random Forest" width="650"/>

---

#### ğŸ”¹ Linear SVM

**AcurÃ¡cia** : 0.9033

<img src="./reports/figures/confusion_matrix_Linear_SVM.png" alt="Matriz de ConfusÃ£o - SVM" width="650"/>

---

### ğŸ ComparaÃ§Ã£o Geral

| Modelo                  | AcurÃ¡cia | Precision | Recall | F1-Score |
| ----------------------- | -------- | --------- | ------ | -------- |
| Logistic Regression     | 0.9041   | 0.9039    | 0.9041 | 0.9039   |
| Linear SVM              | 0.9033   | 0.9031    | 0.9033 | 0.9031   |
| Multinomial Naive Bayes | 0.8882   | 0.8876    | 0.8882 | 0.8878   |
| Random Forest           | 0.8667   | 0.8667    | 0.8667 | 0.8662   |

---

### âœ… ConclusÃ£o

- **Logistic Regression** e **Linear SVM** apresentaram os melhores desempenhos.
- O modelo **Random Forest** teve desempenho inferior, especialmente em categorias com menor volume textual.
- Os resultados indicam que modelos lineares sÃ£o mais eficazes neste contexto, devido Ã  natureza textual vetorizada com TF-IDF.

---

### LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a MIT - veja o arquivo [LICENSE](./LICENSE) para detalhes.

---

### Contato

LinkedIn: [linkedin.com/in/heitorandradeoliveira](https://linkedin.com/in/heitorandradeoliveira)

---
